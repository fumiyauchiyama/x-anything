1: INFO    25-01-19 22:41:23.167325 - 0:00:02 - Epoch 0 started
1: INFO    25-01-19 22:41:27.012447 - 0:00:06 - Epoch 0, iter 0, loss: 40.125633239746094
1: INFO    25-01-19 22:41:27.841912 - 0:00:07 - Epoch 0, iter 1, loss: 38.78356170654297
1: INFO    25-01-19 22:41:28.397136 - 0:00:07 - Epoch 0, iter 2, loss: 38.272926330566406
1: INFO    25-01-19 22:41:28.936101 - 0:00:08 - Epoch 0, iter 3, loss: 38.97425842285156
1: INFO    25-01-19 22:41:29.469628 - 0:00:09 - Epoch 0, iter 4, loss: 38.902626037597656
1: INFO    25-01-19 22:41:30.015210 - 0:00:09 - Epoch 0, iter 5, loss: 38.045780181884766
1: INFO    25-01-19 22:41:30.593206 - 0:00:10 - Epoch 0, iter 6, loss: 36.760894775390625
1: INFO    25-01-19 22:41:31.153138 - 0:00:10 - Epoch 0, iter 7, loss: 35.161170959472656
1: INFO    25-01-19 22:41:31.682430 - 0:00:11 - Epoch 0, iter 8, loss: 35.415714263916016
1: INFO    25-01-19 22:41:32.250286 - 0:00:11 - Epoch 0, iter 9, loss: 34.485713958740234
1: INFO    25-01-19 22:41:32.782928 - 0:00:12 - Epoch 0, iter 10, loss: 33.13985061645508
1: INFO    25-01-19 22:41:33.332218 - 0:00:12 - Epoch 0, iter 11, loss: 30.085485458374023
1: INFO    25-01-19 22:41:33.873651 - 0:00:13 - Epoch 0, iter 12, loss: 30.55120849609375
1: INFO    25-01-19 22:41:34.421244 - 0:00:13 - Epoch 0, iter 13, loss: 28.451618194580078
1: INFO    25-01-19 22:41:34.965877 - 0:00:14 - Epoch 0, iter 14, loss: 28.184362411499023
1: INFO    25-01-19 22:41:35.510327 - 0:00:15 - Epoch 0, iter 15, loss: 27.148670196533203
1: INFO    25-01-19 22:41:36.059459 - 0:00:15 - Epoch 0, iter 16, loss: 24.70088768005371
1: INFO    25-01-19 22:41:36.610551 - 0:00:16 - Epoch 0, iter 17, loss: 23.026708602905273
1: INFO    25-01-19 22:41:37.168012 - 0:00:16 - Epoch 0, iter 18, loss: 21.661197662353516
1: INFO    25-01-19 22:41:37.686212 - 0:00:17 - Epoch 0, iter 19, loss: 19.7926025390625
1: INFO    25-01-19 22:41:38.241803 - 0:00:17 - Epoch 0, iter 20, loss: 18.413463592529297
1: INFO    25-01-19 22:41:38.789686 - 0:00:18 - Epoch 0, iter 21, loss: 17.52680206298828
1: INFO    25-01-19 22:41:39.448720 - 0:00:19 - Epoch 0, iter 22, loss: 20.096445083618164
1: INFO    25-01-19 22:41:39.986392 - 0:00:19 - Epoch 0, iter 23, loss: 15.247217178344727
1: INFO    25-01-19 22:41:40.526664 - 0:00:20 - Epoch 0, iter 24, loss: 17.5544490814209
1: INFO    25-01-19 22:41:41.082447 - 0:00:20 - Epoch 0, iter 25, loss: 14.295013427734375
1: INFO    25-01-19 22:41:41.634360 - 0:00:21 - Epoch 0, iter 26, loss: 13.441144943237305
1: INFO    25-01-19 22:41:42.152423 - 0:00:21 - Epoch 0, iter 27, loss: 30.015913009643555
1: INFO    25-01-19 22:41:42.702603 - 0:00:22 - Epoch 0, iter 28, loss: 12.81129264831543
1: INFO    25-01-19 22:41:43.251976 - 0:00:22 - Epoch 0, iter 29, loss: 16.909645080566406
1: INFO    25-01-19 22:41:43.793068 - 0:00:23 - Epoch 0, iter 30, loss: 12.520387649536133
1: INFO    25-01-19 22:41:44.345706 - 0:00:23 - Epoch 0, iter 31, loss: 12.640312194824219
1: INFO    25-01-19 22:41:44.881744 - 0:00:24 - Epoch 0, iter 32, loss: 12.559113502502441
1: INFO    25-01-19 22:41:45.427855 - 0:00:24 - Epoch 0, iter 33, loss: 12.172991752624512
1: INFO    25-01-19 22:41:45.966962 - 0:00:25 - Epoch 0, iter 34, loss: 11.979422569274902
1: INFO    25-01-19 22:41:46.504533 - 0:00:26 - Epoch 0, iter 35, loss: 11.84156322479248
1: INFO    25-01-19 22:41:47.037979 - 0:00:26 - Epoch 0, iter 36, loss: 12.275054931640625
1: INFO    25-01-19 22:41:47.575086 - 0:00:27 - Epoch 0, iter 37, loss: 14.579461097717285
1: INFO    25-01-19 22:41:48.116850 - 0:00:27 - Epoch 0, iter 38, loss: 11.595874786376953
1: INFO    25-01-19 22:41:48.655693 - 0:00:28 - Epoch 0, iter 39, loss: 11.765085220336914
1: INFO    25-01-19 22:41:49.205449 - 0:00:28 - Epoch 0, iter 40, loss: 12.034038543701172
1: INFO    25-01-19 22:41:49.745607 - 0:00:29 - Epoch 0, iter 41, loss: 11.615096092224121
1: INFO    25-01-19 22:41:50.309968 - 0:00:29 - Epoch 0, iter 42, loss: 11.370525360107422
1: INFO    25-01-19 22:41:50.843598 - 0:00:30 - Epoch 0, iter 43, loss: 11.742671012878418
1: INFO    25-01-19 22:41:51.380309 - 0:00:30 - Epoch 0, iter 44, loss: 13.047494888305664
1: INFO    25-01-19 22:41:51.914582 - 0:00:31 - Epoch 0, iter 45, loss: 13.309123039245605
1: INFO    25-01-19 22:41:52.462649 - 0:00:32 - Epoch 0, iter 46, loss: 11.201133728027344
1: INFO    25-01-19 22:41:52.996198 - 0:00:32 - Epoch 0, iter 47, loss: 11.2754545211792
1: INFO    25-01-19 22:41:53.554049 - 0:00:33 - Epoch 0, iter 48, loss: 11.367284774780273
1: INFO    25-01-19 22:41:54.093099 - 0:00:33 - Epoch 0, iter 49, loss: 11.266852378845215
1: INFO    25-01-19 22:41:54.632813 - 0:00:34 - Epoch 0, iter 50, loss: 11.202227592468262
1: INFO    25-01-19 22:41:55.164458 - 0:00:34 - Epoch 0, iter 51, loss: 11.792631149291992
1: INFO    25-01-19 22:41:55.712042 - 0:00:35 - Epoch 0, iter 52, loss: 33.01066589355469
1: INFO    25-01-19 22:41:56.248364 - 0:00:35 - Epoch 0, iter 53, loss: 11.46976089477539
1: INFO    25-01-19 22:41:56.777768 - 0:00:36 - Epoch 0, iter 54, loss: 11.298354148864746
1: INFO    25-01-19 22:41:57.401040 - 0:00:36 - Epoch 0, iter 55, loss: 11.400086402893066
1: INFO    25-01-19 22:41:57.962324 - 0:00:37 - Epoch 0, iter 56, loss: 12.789297103881836
1: INFO    25-01-19 22:41:58.504040 - 0:00:38 - Epoch 0, iter 57, loss: 12.11992073059082
1: INFO    25-01-19 22:41:59.043543 - 0:00:38 - Epoch 0, iter 58, loss: 22.429370880126953
1: INFO    25-01-19 22:41:59.578575 - 0:00:39 - Epoch 0, iter 59, loss: 12.019166946411133
1: INFO    25-01-19 22:42:00.123570 - 0:00:39 - Epoch 0, iter 60, loss: 12.072213172912598
1: INFO    25-01-19 22:42:00.667734 - 0:00:40 - Epoch 0, iter 61, loss: 25.966535568237305
1: INFO    25-01-19 22:42:01.213952 - 0:00:40 - Epoch 0, iter 62, loss: 12.766290664672852
1: INFO    25-01-19 22:42:01.772267 - 0:00:41 - Epoch 0, iter 63, loss: 13.034854888916016
1: INFO    25-01-19 22:42:02.334022 - 0:00:41 - Epoch 0, iter 64, loss: 15.02751350402832
1: INFO    25-01-19 22:42:02.877847 - 0:00:42 - Epoch 0, iter 65, loss: 13.313140869140625
1: INFO    25-01-19 22:42:03.422251 - 0:00:42 - Epoch 0, iter 66, loss: 13.204021453857422
1: INFO    25-01-19 22:42:03.969625 - 0:00:43 - Epoch 0, iter 67, loss: 13.214903831481934
1: INFO    25-01-19 22:42:04.511874 - 0:00:44 - Epoch 0, iter 68, loss: 12.4957857131958
1: INFO    25-01-19 22:42:05.055180 - 0:00:44 - Epoch 0, iter 69, loss: 12.534621238708496
1: INFO    25-01-19 22:42:05.598721 - 0:00:45 - Epoch 0, iter 70, loss: 11.805180549621582
1: INFO    25-01-19 22:42:06.175189 - 0:00:45 - Epoch 0, iter 71, loss: 11.767036437988281
1: INFO    25-01-19 22:42:06.881206 - 0:00:46 - Epoch 0, iter 72, loss: 12.65900993347168
1: INFO    25-01-19 22:42:07.421305 - 0:00:46 - Epoch 0, iter 73, loss: 11.357197761535645
1: INFO    25-01-19 22:42:07.963362 - 0:00:47 - Epoch 0, iter 74, loss: 11.800799369812012
1: INFO    25-01-19 22:42:08.504367 - 0:00:48 - Epoch 0, iter 75, loss: 17.184764862060547
1: INFO    25-01-19 22:42:09.032256 - 0:00:48 - Epoch 0, iter 76, loss: 11.473003387451172
1: INFO    25-01-19 22:42:09.566707 - 0:00:49 - Epoch 0, iter 77, loss: 11.747597694396973
1: INFO    25-01-19 22:42:10.109724 - 0:00:49 - Epoch 0, iter 78, loss: 11.36188793182373
1: INFO    25-01-19 22:42:10.650317 - 0:00:50 - Epoch 0, iter 79, loss: 11.481003761291504
1: INFO    25-01-19 22:42:11.196334 - 0:00:50 - Epoch 0, iter 80, loss: 11.619023323059082
1: INFO    25-01-19 22:42:11.735257 - 0:00:51 - Epoch 0, iter 81, loss: 11.226539611816406
1: INFO    25-01-19 22:42:12.275049 - 0:00:51 - Epoch 0, iter 82, loss: 11.679726600646973
1: INFO    25-01-19 22:42:12.818144 - 0:00:52 - Epoch 0, iter 83, loss: 11.274164199829102
1: INFO    25-01-19 22:42:13.360311 - 0:00:52 - Epoch 0, iter 84, loss: 11.173165321350098
1: INFO    25-01-19 22:42:13.897340 - 0:00:53 - Epoch 0, iter 85, loss: 32.006011962890625
1: INFO    25-01-19 22:42:14.440104 - 0:00:53 - Epoch 0, iter 86, loss: 11.217382431030273
1: INFO    25-01-19 22:42:14.983249 - 0:00:54 - Epoch 0, iter 87, loss: 11.38388729095459
1: INFO    25-01-19 22:42:15.520998 - 0:00:55 - Epoch 0, iter 88, loss: 11.468708038330078
1: INFO    25-01-19 22:42:16.070098 - 0:00:55 - Epoch 0, iter 89, loss: 11.733640670776367
1: INFO    25-01-19 22:42:16.592888 - 0:00:56 - Epoch 0, iter 90, loss: 11.88076400756836
1: INFO    25-01-19 22:42:17.145478 - 0:00:56 - Epoch 0, iter 91, loss: 11.646121978759766
1: INFO    25-01-19 22:42:17.683597 - 0:00:57 - Epoch 0, iter 92, loss: 19.337100982666016
Traceback (most recent call last):
  File "/home/fumiyauchiyama/anaconda3/envs/py10/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/fumiyauchiyama/anaconda3/envs/py10/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/fumiyauchiyama/repos/x-anything/scripts/main/train.py", line 33, in <module>
    main()
  File "/home/fumiyauchiyama/repos/x-anything/scripts/main/train.py", line 30, in main
    trainer.train()
  File "/home/fumiyauchiyama/repos/x-anything/scripts/main/trainer.py", line 368, in train
    self.train_one_epoch(epoch, step)
  File "/home/fumiyauchiyama/repos/x-anything/scripts/main/trainer.py", line 342, in train_one_epoch
    loss[CORE_LOSS_KEY].backward()
  File "/home/fumiyauchiyama/anaconda3/envs/py10/lib/python3.10/site-packages/torch/_tensor.py", line 581, in backward
    torch.autograd.backward(
  File "/home/fumiyauchiyama/anaconda3/envs/py10/lib/python3.10/site-packages/torch/autograd/__init__.py", line 347, in backward
    _engine_run_backward(
  File "/home/fumiyauchiyama/anaconda3/envs/py10/lib/python3.10/site-packages/torch/autograd/graph.py", line 825, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
[rank1]: Traceback (most recent call last):
[rank1]:   File "/home/fumiyauchiyama/anaconda3/envs/py10/lib/python3.10/runpy.py", line 196, in _run_module_as_main
[rank1]:     return _run_code(code, main_globals, None,
[rank1]:   File "/home/fumiyauchiyama/anaconda3/envs/py10/lib/python3.10/runpy.py", line 86, in _run_code
[rank1]:     exec(code, run_globals)
[rank1]:   File "/home/fumiyauchiyama/repos/x-anything/scripts/main/train.py", line 33, in <module>
[rank1]:     main()
[rank1]:   File "/home/fumiyauchiyama/repos/x-anything/scripts/main/train.py", line 30, in main
[rank1]:     trainer.train()
[rank1]:   File "/home/fumiyauchiyama/repos/x-anything/scripts/main/trainer.py", line 368, in train
[rank1]:     self.train_one_epoch(epoch, step)
[rank1]:   File "/home/fumiyauchiyama/repos/x-anything/scripts/main/trainer.py", line 342, in train_one_epoch
[rank1]:     loss[CORE_LOSS_KEY].backward()
[rank1]:   File "/home/fumiyauchiyama/anaconda3/envs/py10/lib/python3.10/site-packages/torch/_tensor.py", line 581, in backward
[rank1]:     torch.autograd.backward(
[rank1]:   File "/home/fumiyauchiyama/anaconda3/envs/py10/lib/python3.10/site-packages/torch/autograd/__init__.py", line 347, in backward
[rank1]:     _engine_run_backward(
[rank1]:   File "/home/fumiyauchiyama/anaconda3/envs/py10/lib/python3.10/site-packages/torch/autograd/graph.py", line 825, in _engine_run_backward
[rank1]:     return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank1]: KeyboardInterrupt
